"""
Multi-Agent Chatbot UI
======================
Gradio ê¸°ë°˜ ì›¹ ì¸í„°í˜ì´ìŠ¤

Layout:
- Row 1: ì±„íŒ… ì˜ì—­ (ëŒ€í™”ì°½, ì…ë ¥ì°½)
- Row 2: íƒ­ íŒ¨ë„ (LLM Settings, Workspace Files, SharedStorage, History, HTML Preview, SystemPrompt)
"""

import os
import sys
import time
import json
import warnings
from datetime import datetime
from typing import List, Tuple, Generator, Optional, Dict

# Gradio ë‚´ë¶€ DeprecationWarning ìˆ¨ê¸°ê¸° (starlette í˜¸í™˜ì„± ë¬¸ì œ)
warnings.filterwarnings("ignore", category=DeprecationWarning, module="gradio")

import gradio as gr

# ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from core.shared_storage import SharedStorage
from core.base_tool import ToolRegistry
from core.orchestrator import Orchestrator, LLMConfig, StepInfo, StepType
from core.workspace_manager import WorkspaceManager, ConfigManager, FileInfo
from core.html_utils import HTMLParser, store_html, get_html
from tools.file_tool import FileTool
from tools.web_tool import WebTool
from tools.llm_tool import LLMTool


# =============================================================================
# Global State
# =============================================================================

class AppState:
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒíƒœ ê´€ë¦¬"""
    
    def __init__(self, workspace_path: str = os.path.join(".", "workspace")):
        self.workspace_path = workspace_path
        
        # ë§¤ë‹ˆì € ì´ˆê¸°í™”
        self.workspace_manager = WorkspaceManager(workspace_path)
        self.config_manager = ConfigManager(os.path.join(workspace_path, "config"))
        
        # LLM ì„¤ì • ë¡œë“œ
        self.llm_config = self.config_manager.load_llm_config()
        
        # Core ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.storage = SharedStorage(debug_enabled=True)
        self.registry = ToolRegistry(debug_enabled=True)
        
        # Tools ë“±ë¡
        self._setup_tools()
        
        # Orchestrator ìƒì„±
        self.orchestrator = Orchestrator(
            tools=self.registry,
            storage=self.storage,
            llm_config=self.llm_config,
            max_steps=self.llm_config.max_steps if hasattr(self.llm_config, 'max_steps') else 10,
            debug_enabled=True
        )
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ (UIìš©)
        self.chat_history: List[Dict] = []
        
        # System Prompt íˆìŠ¤í† ë¦¬ (NEW)
        self.system_prompt_history: List[Dict] = []
    
    def _setup_tools(self):
        """Tools ì„¤ì •"""
        files_dir = os.path.join(self.workspace_path, "files")
        os.makedirs(files_dir, exist_ok=True)
        
        self.registry.register(FileTool(base_path=files_dir, debug_enabled=True))
        self.registry.register(WebTool(debug_enabled=True, use_mock=False))
        self.registry.register(LLMTool(debug_enabled=True, use_mock=False))
    
    def update_llm_config(self, **kwargs):
        """LLM ì„¤ì • ì—…ë°ì´íŠ¸ ë° ì €ì¥"""
        self.llm_config.update(**kwargs)
        self.orchestrator.update_llm_config(**kwargs)
        self.config_manager.save_llm_config(self.llm_config)
    
    def get_available_models(self, base_url: str = None) -> List[str]:
        """Ollama ì„œë²„ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ"""
        if base_url is None:
            base_url = self.llm_config.base_url
        
        try:
            import requests
            response = requests.get(f"{base_url}/api/tags", timeout=5)
            response.raise_for_status()
            data = response.json()
            
            models = [model["name"] for model in data.get("models", [])]
            if models:
                return sorted(models)
        except Exception as e:
            print(f"[WARN] Ollama ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        # Fallback: ê¸°ë³¸ ëª©ë¡
        return ["llama3.2", "llama3.1", "codellama", "mistral", "gemma2", "qwen2.5"]
    
    def add_system_prompt_history(self, prompt: str, step: int):
        """System Prompt íˆìŠ¤í† ë¦¬ ì¶”ê°€"""
        self.system_prompt_history.append({
            "step": step,
            "timestamp": datetime.now().isoformat(),
            "prompt": prompt
        })


# ì „ì—­ ìƒíƒœ
app_state: Optional[AppState] = None


def get_app_state() -> AppState:
    """ì•± ìƒíƒœ ê°€ì ¸ì˜¤ê¸° (lazy initialization)"""
    global app_state
    if app_state is None:
        app_state = AppState()
    return app_state


# =============================================================================
# Chat Functions
# =============================================================================

def format_tool_result(content: str, tool_name: str, action: str) -> str:
    """Tool ê²°ê³¼ë¥¼ í¬ë§·íŒ… (HTML ê°ì§€ í¬í•¨)"""
    content_str = str(content)
    
    # HTML ê°ì§€ ë° íŠ¹ë³„ ì²˜ë¦¬
    if tool_name == "web_tool" and action == "fetch" and HTMLParser.is_html(content_str):
        # HTML ì €ì¥ ë° ìš”ì•½ ìƒì„±
        html_hash = store_html(content_str)
        summary = HTMLParser.summarize(content_str)
        
        warning = ""
        if summary.has_scripts:
            warning += "âš ï¸ ìŠ¤í¬ë¦½íŠ¸ í¬í•¨ "
        if summary.has_forms:
            warning += "âš ï¸ í¼ í¬í•¨ "
        
        size_kb = summary.char_count / 1024
        
        return f"""ğŸ“„ **{summary.title}**

{summary.text_preview}

ğŸ“Š í¬ê¸°: {size_kb:.1f}KB {warning}

ğŸ”‘ HTML ID: `{html_hash}` (ë¯¸ë¦¬ë³´ê¸°/ë³µì‚¬ì— ì‚¬ìš©)"""
    
    # ì¼ë°˜ ê²°ê³¼
    if len(content_str) > 500:
        content_str = content_str[:500] + "\n... (truncated)"
    return f"```\n{content_str}\n```"


def chat_stream(message: str, history: List[Dict]) -> Generator[Tuple[List[Dict], str], None, None]:
    """ì±„íŒ… ë©”ì‹œì§€ ì²˜ë¦¬ (Streaming)"""
    state = get_app_state()
    
    if not message.strip():
        yield history, "ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
        return
    
    # íŒŒì¼ ëª©ë¡ì„ contextì— ì¶”ê°€
    files_context = state.workspace_manager.get_files_for_prompt()
    full_query = f"{message}\n\n{files_context}"
    
    # ìƒˆ ëŒ€í™” ì¶”ê°€ (Gradio 6.0 í˜•ì‹)
    history = history + [
        {"role": "user", "content": message},
        {"role": "assistant", "content": ""}
    ]
    current_response = ""
    step_outputs = []
    
    yield history, "ğŸ”„ ì²˜ë¦¬ ì¤‘..."
    
    try:
        for step in state.orchestrator.run_stream(full_query):
            if step.type == StepType.THINKING:
                yield history, f"ğŸ’­ {step.content}"
            
            elif step.type == StepType.TOOL_CALL:
                step_output = f"\n\n<details>\n<summary>ğŸ”§ Step {step.step}: {step.tool_name}.{step.action}</summary>\n\n"
                step_outputs.append({
                    "header": step_output, 
                    "result": "",
                    "tool_name": step.tool_name,
                    "action": step.action
                })
                yield history, f"ğŸ”§ {step.tool_name}.{step.action} ì‹¤í–‰ ì¤‘..."
            
            elif step.type == StepType.TOOL_RESULT:
                if step_outputs:
                    last_step = step_outputs[-1]
                    formatted_result = format_tool_result(
                        step.content, 
                        last_step.get("tool_name", ""),
                        last_step.get("action", "")
                    )
                    step_outputs[-1]["result"] = f"{formatted_result}\n</details>"
                yield history, f"âœ… {step.tool_name}.{step.action} ì™„ë£Œ"
            
            elif step.type == StepType.FINAL_ANSWER:
                # ìµœì¢… ì‘ë‹µ êµ¬ì„±
                steps_md = ""
                for s in step_outputs:
                    steps_md += s["header"] + s["result"]
                
                current_response = step.content
                if steps_md:
                    current_response = steps_md + "\n\n---\n\n" + current_response
                
                history[-1] = {"role": "assistant", "content": current_response}
                yield history, "âœ… ì™„ë£Œ"
            
            elif step.type == StepType.ERROR:
                current_response = f"âŒ **ì˜¤ë¥˜ ë°œìƒ**\n\n{step.content}"
                history[-1] = {"role": "assistant", "content": current_response}
                yield history, "âŒ ì˜¤ë¥˜ ë°œìƒ"
    
    except Exception as e:
        error_msg = f"âŒ **ì˜ˆì™¸ ë°œìƒ**\n\n{str(e)}"
        history[-1] = {"role": "assistant", "content": error_msg}
        yield history, f"âŒ {str(e)}"
    
    # íˆìŠ¤í† ë¦¬ ì €ì¥
    state.chat_history = history


def stop_generation():
    """ìƒì„± ì¤‘ì§€"""
    state = get_app_state()
    state.orchestrator.stop()
    return "â¹ï¸ ì¤‘ì§€ë¨"


def clear_chat():
    """ëŒ€í™” ì´ˆê¸°í™”"""
    state = get_app_state()
    state.chat_history = []
    state.storage.reset()  # SharedStorageë„ ì´ˆê¸°í™”
    state.system_prompt_history = []  # System Prompt íˆìŠ¤í† ë¦¬ë„ ì´ˆê¸°í™”
    return [], "ëŒ€í™”ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤."


# =============================================================================
# LLM Settings Functions
# =============================================================================

def update_model(model: str) -> str:
    get_app_state().update_llm_config(model=model)
    return f"âœ… Model: {model}"

def update_temperature(temp: float) -> str:
    get_app_state().update_llm_config(temperature=temp)
    return f"âœ… Temperature: {temp}"

def update_max_tokens(tokens: int) -> str:
    get_app_state().update_llm_config(max_tokens=tokens)
    return f"âœ… Max Tokens: {tokens}"

def update_top_p(top_p: float) -> str:
    get_app_state().update_llm_config(top_p=top_p)
    return f"âœ… Top-p: {top_p}"

def update_repeat_penalty(penalty: float) -> str:
    get_app_state().update_llm_config(repeat_penalty=penalty)
    return f"âœ… Repeat Penalty: {penalty}"

def update_num_ctx(num_ctx: int) -> str:
    get_app_state().update_llm_config(num_ctx=num_ctx)
    return f"âœ… Context Window: {num_ctx}"

def update_max_steps(steps: int) -> str:
    state = get_app_state()
    state.orchestrator.max_steps = steps
    return f"âœ… Max Steps: {steps}"

def update_base_url(url: str) -> str:
    get_app_state().update_llm_config(base_url=url)
    return f"âœ… Base URL: {url}"

def refresh_models(base_url: str) -> Tuple[gr.update, str]:
    """ëª¨ë¸ ëª©ë¡ ìƒˆë¡œê³ ì¹¨"""
    state = get_app_state()
    
    # URL ì—…ë°ì´íŠ¸
    if base_url != state.llm_config.base_url:
        state.update_llm_config(base_url=base_url)
    
    # ëª¨ë¸ ëª©ë¡ ì¡°íšŒ
    models = state.get_available_models(base_url)
    current_model = state.llm_config.model
    
    # í˜„ì¬ ëª¨ë¸ì´ ëª©ë¡ì— ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ëª¨ë¸ë¡œ ë³€ê²½
    if current_model not in models and models:
        current_model = models[0]
        state.update_llm_config(model=current_model)
    
    return gr.update(choices=models, value=current_model), f"âœ… {len(models)}ê°œ ëª¨ë¸ ë¡œë“œë¨"

def reset_settings():
    """ì„¤ì • ì´ˆê¸°í™”"""
    state = get_app_state()
    default = LLMConfig()
    
    state.update_llm_config(
        model=default.model,
        temperature=default.temperature,
        max_tokens=default.max_tokens,
        top_p=default.top_p,
        repeat_penalty=default.repeat_penalty,
        num_ctx=default.num_ctx,
        base_url=default.base_url
    )
    state.orchestrator.max_steps = 10
    
    models = state.get_available_models()
    
    return (
        gr.update(choices=models, value=default.model),
        default.temperature,
        default.max_tokens,
        default.top_p,
        default.repeat_penalty,
        default.num_ctx,
        10,
        default.base_url,
        "âœ… ì„¤ì • ì´ˆê¸°í™”ë¨"
    )


# =============================================================================
# File Management Functions
# =============================================================================

def upload_files(files) -> Tuple[str, str]:
    """íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬"""
    state = get_app_state()
    
    if not files:
        return get_file_list_html(), "íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”."
    
    uploaded = []
    for file in files:
        file_info = state.workspace_manager.save_upload(file.name)
        if file_info:
            uploaded.append(file_info.name)
    
    if uploaded:
        return get_file_list_html(), f"âœ… {len(uploaded)}ê°œ íŒŒì¼ ì—…ë¡œë“œë¨"
    return get_file_list_html(), "âŒ ì—…ë¡œë“œ ì‹¤íŒ¨"


def get_file_list_html() -> str:
    """íŒŒì¼ ëª©ë¡ HTML ìƒì„±"""
    state = get_app_state()
    files = state.workspace_manager.list_files()
    
    if not files:
        return "<p style='color: gray;'>íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.</p>"
    
    html = "<table style='width:100%; border-collapse:collapse;'>"
    html += "<tr style='background:#f0f0f0;'><th>ì´ë¦„</th><th>í¬ê¸°</th><th>ì¶œì²˜</th></tr>"
    
    for f in files:
        size = f"{f.size / 1024:.1f}KB" if f.size >= 1024 else f"{f.size}B"
        source = "ğŸ“¤ ì—…ë¡œë“œ" if f.source == "upload" else "ğŸ¤– ìƒì„±"
        html += f"<tr><td>{f.name}</td><td>{size}</td><td>{source}</td></tr>"
    
    html += "</table>"
    return html


def get_file_choices() -> List[str]:
    """íŒŒì¼ ì„ íƒ ëª©ë¡"""
    state = get_app_state()
    files = state.workspace_manager.list_files()
    return [f.name for f in files]


def delete_selected_files(selected: List[str]) -> Tuple[str, str, gr.update]:
    """ì„ íƒëœ íŒŒì¼ ì‚­ì œ"""
    state = get_app_state()
    
    if not selected:
        return get_file_list_html(), "ì‚­ì œí•  íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.", gr.update(choices=get_file_choices())
    
    deleted = 0
    for name in selected:
        if state.workspace_manager.delete_file(name):
            deleted += 1
    
    return get_file_list_html(), f"âœ… {deleted}ê°œ íŒŒì¼ ì‚­ì œë¨", gr.update(choices=get_file_choices(), value=[])


def delete_all_files() -> Tuple[str, str, gr.update]:
    """ì „ì²´ íŒŒì¼ ì‚­ì œ"""
    state = get_app_state()
    count = state.workspace_manager.clear_all_files()
    return get_file_list_html(), f"âœ… {count}ê°œ íŒŒì¼ ì‚­ì œë¨", gr.update(choices=[], value=[])


def refresh_file_list() -> Tuple[str, gr.update]:
    """íŒŒì¼ ëª©ë¡ ìƒˆë¡œê³ ì¹¨"""
    return get_file_list_html(), gr.update(choices=get_file_choices())


# =============================================================================
# SharedStorage Functions (NEW)
# =============================================================================

def get_shared_storage_tree() -> str:
    """SharedStorage ë‚´ìš©ì„ íŠ¸ë¦¬ë·° í˜•íƒœë¡œ HTML ìƒì„±"""
    state = get_app_state()
    storage = state.storage
    
    html = "<div style='font-family: monospace; font-size: 13px;'>"
    
    # Context
    context = storage.get_context()  # None ë˜ëŠ” Dict
    html += "<details open><summary><b>ğŸ“ Context</b></summary>"
    html += "<div style='margin-left: 20px;'>"
    
    if context:
        user_query = context.get('user_query', 'N/A')
        if user_query and len(user_query) > 50:
            user_query = user_query[:50] + "..."
        html += f"<div>user_query: <code>{user_query}</code></div>"
        html += f"<div>current_step: <code>{context.get('current_step', 0)}</code></div>"
        html += f"<div>session_id: <code>{context.get('session_id', 'N/A')}</code></div>"
    else:
        html += "<div style='color: gray;'>ì„¸ì…˜ ì—†ìŒ</div>"
    
    html += "</div></details>"
    
    # Results
    results = storage.get_results()
    html += f"<details open><summary><b>ğŸ“ Results ({len(results)})</b></summary>"
    html += "<div style='margin-left: 20px;'>"
    
    if not results:
        html += "<div style='color: gray;'>ê²°ê³¼ ì—†ìŒ</div>"
    else:
        for i, r in enumerate(results):
            status_icon = "âœ…" if r.get("status") == "success" else "âŒ"
            tool = r.get("tool", "unknown")
            action = r.get("action", "unknown")
            output_preview = str(r.get("output", ""))[:100]
            
            html += f"<details><summary>{status_icon} Step {i+1}: {tool}.{action}</summary>"
            html += f"<div style='margin-left: 20px; background: #f5f5f5; padding: 8px; border-radius: 4px;'>"
            html += f"<pre style='white-space: pre-wrap; margin: 0;'>{output_preview}...</pre>"
            html += "</div></details>"
    
    html += "</div></details>"
    
    # History
    history = storage.get_history()
    html += f"<details><summary><b>ğŸ“ History ({len(history)})</b></summary>"
    html += "<div style='margin-left: 20px;'>"
    
    if not history:
        html += "<div style='color: gray;'>íˆìŠ¤í† ë¦¬ ì—†ìŒ</div>"
    else:
        for i, h in enumerate(history[-5:]):  # ìµœê·¼ 5ê°œë§Œ
            query = h.get("user_query", "")[:30]
            status = "âœ…" if h.get("status") == "completed" else "âš ï¸"
            html += f"<div>{status} {query}...</div>"
    
    html += "</div></details>"
    
    html += "</div>"
    return html

def refresh_shared_storage() -> str:
    """SharedStorage ìƒˆë¡œê³ ì¹¨"""
    return get_shared_storage_tree()


# =============================================================================
# History Functions
# =============================================================================

def get_history_html() -> str:
    """ëŒ€í™” íˆìŠ¤í† ë¦¬ HTML"""
    state = get_app_state()
    history_data = state.storage.get_history()
    
    if not history_data:
        return "<p style='color: gray;'>íˆìŠ¤í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.</p>"
    
    html = ""
    for i, session in enumerate(reversed(history_data[-10:])):  # ìµœê·¼ 10ê°œ
        query = session.get("user_query", "")[:50]
        if len(session.get("user_query", "")) > 50:
            query += "..."
        
        status_icon = "âœ…" if session.get("status") == "completed" else "âš ï¸"
        time_str = session.get("created_at", "")[:16]
        
        html += f"""
        <div style='padding:8px; margin:4px 0; background:#f5f5f5; border-radius:4px;'>
            <span>{status_icon}</span>
            <strong>{query}</strong>
            <span style='color:gray; font-size:0.8em;'>{time_str}</span>
        </div>
        """
    
    return html


# =============================================================================
# HTML Preview Functions
# =============================================================================

def preview_html(html_hash: str) -> Tuple[str, str]:
    """HTML ë¯¸ë¦¬ë³´ê¸° ìƒì„±"""
    if not html_hash.strip():
        return "", "âŒ HTML IDë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
    
    html_content = get_html(html_hash.strip())
    if not html_content:
        return "", f"âŒ HTMLì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {html_hash}"
    
    # iframeìš©ìœ¼ë¡œ ì •ë¦¬
    sanitized = HTMLParser.sanitize_for_iframe(html_content)
    
    # iframe HTML ìƒì„±
    iframe_html = f'''<iframe 
        srcdoc="{sanitized.replace('"', '&quot;')}" 
        style="width:100%; height:400px; border:1px solid #ddd; border-radius:8px;"
        sandbox="allow-same-origin">
    </iframe>'''
    
    return iframe_html, f"âœ… HTML ë¯¸ë¦¬ë³´ê¸° ë¡œë“œë¨ ({html_hash})"


def get_html_source(html_hash: str) -> Tuple[str, str]:
    """HTML ì†ŒìŠ¤ ê°€ì ¸ì˜¤ê¸°"""
    if not html_hash.strip():
        return "", "âŒ HTML IDë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
    
    html_content = get_html(html_hash.strip())
    if not html_content:
        return "", f"âŒ HTMLì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {html_hash}"
    
    return html_content, f"âœ… HTML ì†ŒìŠ¤ ë¡œë“œë¨ ({len(html_content):,} bytes)"


# =============================================================================
# System Prompt Functions (NEW)
# =============================================================================

def get_system_prompt_html() -> str:
    """í˜„ì¬ System Promptë¥¼ HTMLë¡œ í‘œì‹œ"""
    state = get_app_state()
    
    # í˜„ì¬ system prompt ê°€ì ¸ì˜¤ê¸°
    current_prompt = state.orchestrator._build_system_prompt()
    
    html = "<div style='font-family: monospace; font-size: 12px;'>"
    
    # í˜„ì¬ í”„ë¡¬í”„íŠ¸
    html += "<h4>ğŸ“ í˜„ì¬ System Prompt</h4>"
    html += f"<pre style='background: #f5f5f5; padding: 10px; border-radius: 4px; white-space: pre-wrap; max-height: 400px; overflow-y: auto;'>{current_prompt}</pre>"
    
    # íˆìŠ¤í† ë¦¬
    if state.system_prompt_history:
        html += f"<h4>ğŸ“œ ë³€ê²½ íˆìŠ¤í† ë¦¬ ({len(state.system_prompt_history)})</h4>"
        for i, item in enumerate(reversed(state.system_prompt_history[-5:])):
            html += f"<details><summary>Step {item['step']} - {item['timestamp'][:19]}</summary>"
            html += f"<pre style='background: #fafafa; padding: 8px; font-size: 11px; max-height: 200px; overflow-y: auto;'>{item['prompt'][:500]}...</pre>"
            html += "</details>"
    
    html += "</div>"
    return html


def refresh_system_prompt() -> str:
    """System Prompt ìƒˆë¡œê³ ì¹¨"""
    return get_system_prompt_html()


# =============================================================================
# Build UI
# =============================================================================

def create_ui() -> gr.Blocks:
    """Gradio UI ìƒì„± - 2í–‰ ë ˆì´ì•„ì›ƒ"""
    
    # ì´ˆê¸° ìƒíƒœ ë¡œë“œ
    state = get_app_state()
    config = state.llm_config
    
    # ëª¨ë¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    available_models = state.get_available_models()
    current_model = config.model
    if current_model not in available_models:
        if available_models:
            current_model = available_models[0]
            state.update_llm_config(model=current_model)
    
    with gr.Blocks(title="Multi-Agent Chatbot", theme=gr.themes.Soft()) as app:
        
        gr.Markdown("# ğŸ¤– Multi-Agent Chatbot")
        
        # =================================================================
        # Row 1: ì±„íŒ… ì˜ì—­
        # =================================================================
        with gr.Column():
            chatbot = gr.Chatbot(
                label="ëŒ€í™”",
                elem_classes=["chatbot"],
                height=400
            )
            
            with gr.Row():
                msg_input = gr.Textbox(
                    placeholder="ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...",
                    label="",
                    scale=8,
                    container=False
                )
                send_btn = gr.Button("ì „ì†¡", variant="primary", scale=1)
                stop_btn = gr.Button("ì¤‘ì§€", variant="stop", scale=1)
            
            with gr.Row():
                clear_btn = gr.Button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”", size="sm")
                status_text = gr.Markdown("Ready")
        
        gr.Markdown("---")
        
        # =================================================================
        # Row 2: íƒ­ íŒ¨ë„
        # =================================================================
        with gr.Tabs():
            
            # ---------------------------------------------------------
            # Tab 1: LLM Settings
            # ---------------------------------------------------------
            with gr.TabItem("âš™ï¸ LLM Settings"):
                with gr.Row():
                    base_url_input = gr.Textbox(
                        value=config.base_url,
                        label="Ollama URL",
                        scale=2
                    )
                    refresh_models_btn = gr.Button("ğŸ”„ ëª¨ë¸ ìƒˆë¡œê³ ì¹¨", size="sm", scale=1)
                
                with gr.Row():
                    model_dropdown = gr.Dropdown(
                        choices=available_models,
                        value=current_model,
                        label="Model",
                        allow_custom_value=True
                    )
                    temperature_slider = gr.Slider(
                        minimum=0.0, maximum=2.0, step=0.1,
                        value=config.temperature,
                        label="Temperature"
                    )
                    max_tokens_slider = gr.Slider(
                        minimum=256, maximum=4096, step=256,
                        value=config.max_tokens,
                        label="Max Tokens"
                    )
                
                with gr.Row():
                    top_p_slider = gr.Slider(
                        minimum=0.0, maximum=1.0, step=0.05,
                        value=config.top_p,
                        label="Top-p"
                    )
                    repeat_penalty_slider = gr.Slider(
                        minimum=1.0, maximum=2.0, step=0.1,
                        value=config.repeat_penalty,
                        label="Repeat Penalty"
                    )
                    num_ctx_slider = gr.Slider(
                        minimum=2048, maximum=8192, step=1024,
                        value=config.num_ctx,
                        label="Context Window"
                    )
                
                with gr.Row():
                    max_steps_slider = gr.Slider(
                        minimum=1, maximum=20, step=1,
                        value=10,
                        label="Max Steps"
                    )
                    reset_btn = gr.Button("ğŸ”„ Reset to Default", size="sm")
                
                settings_status = gr.Markdown("")
            
            # ---------------------------------------------------------
            # Tab 2: Workspace Files
            # ---------------------------------------------------------
            with gr.TabItem("ğŸ“ Workspace Files"):
                with gr.Row():
                    file_upload = gr.File(
                        label="íŒŒì¼ ì—…ë¡œë“œ",
                        file_count="multiple",
                        file_types=None
                    )
                    upload_btn = gr.Button("ğŸ“¤ ì—…ë¡œë“œ", size="sm")
                
                file_list_html = gr.HTML(get_file_list_html())
                
                with gr.Row():
                    file_select = gr.CheckboxGroup(
                        choices=get_file_choices(),
                        label="ì‚­ì œí•  íŒŒì¼ ì„ íƒ"
                    )
                
                with gr.Row():
                    delete_selected_btn = gr.Button("ğŸ—‘ï¸ ì„ íƒ ì‚­ì œ", size="sm")
                    delete_all_btn = gr.Button("ğŸ—‘ï¸ ì „ì²´ ì‚­ì œ", size="sm", variant="stop")
                    refresh_files_btn = gr.Button("ğŸ”„ ìƒˆë¡œê³ ì¹¨", size="sm")
                
                file_status = gr.Markdown("")
            
            # ---------------------------------------------------------
            # Tab 3: SharedStorage (NEW)
            # ---------------------------------------------------------
            with gr.TabItem("ğŸ’¾ SharedStorage"):
                storage_tree = gr.HTML(get_shared_storage_tree())
                refresh_storage_btn = gr.Button("ğŸ”„ ìƒˆë¡œê³ ì¹¨", size="sm")
            
            # ---------------------------------------------------------
            # Tab 4: History
            # ---------------------------------------------------------
            with gr.TabItem("ğŸ“œ History"):
                history_html = gr.HTML(get_history_html())
                refresh_history_btn = gr.Button("ğŸ”„ ìƒˆë¡œê³ ì¹¨", size="sm")
            
            # ---------------------------------------------------------
            # Tab 5: HTML Preview
            # ---------------------------------------------------------
            with gr.TabItem("ğŸŒ HTML ë¯¸ë¦¬ë³´ê¸°"):
                with gr.Row():
                    html_hash_input = gr.Textbox(
                        placeholder="HTML IDë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: a1b2c3d4e5f6)",
                        label="HTML ID",
                        scale=3
                    )
                    preview_btn = gr.Button("ğŸ” ë¯¸ë¦¬ë³´ê¸°", size="sm", scale=1)
                    copy_btn = gr.Button("ğŸ“‹ ì†ŒìŠ¤ë³µì‚¬", size="sm", scale=1)
                
                html_preview_status = gr.Markdown("")
                html_preview_frame = gr.HTML("")
                
                with gr.Accordion("ğŸ“„ HTML ì†ŒìŠ¤", open=False):
                    html_source_text = gr.Textbox(
                        label="HTML Source",
                        lines=15,
                        max_lines=30
                    )
            
            # ---------------------------------------------------------
            # Tab 6: System Prompt (NEW)
            # ---------------------------------------------------------
            with gr.TabItem("ğŸ“ System Prompt"):
                system_prompt_html = gr.HTML(get_system_prompt_html())
                refresh_prompt_btn = gr.Button("ğŸ”„ ìƒˆë¡œê³ ì¹¨", size="sm")
        
        # =================================================================
        # Event Handlers
        # =================================================================
        
        # Chat events
        def on_chat_complete():
            """ì±„íŒ… ì™„ë£Œ í›„ ì—…ë°ì´íŠ¸"""
            return (
                get_history_html(),
                get_shared_storage_tree(),
                get_system_prompt_html()
            )
        
        msg_input.submit(
            fn=chat_stream,
            inputs=[msg_input, chatbot],
            outputs=[chatbot, status_text]
        ).then(
            fn=lambda: "",
            outputs=[msg_input]
        ).then(
            fn=on_chat_complete,
            outputs=[history_html, storage_tree, system_prompt_html]
        )
        
        send_btn.click(
            fn=chat_stream,
            inputs=[msg_input, chatbot],
            outputs=[chatbot, status_text]
        ).then(
            fn=lambda: "",
            outputs=[msg_input]
        ).then(
            fn=on_chat_complete,
            outputs=[history_html, storage_tree, system_prompt_html]
        )
        
        stop_btn.click(fn=stop_generation, outputs=[status_text])
        clear_btn.click(
            fn=clear_chat, 
            outputs=[chatbot, status_text]
        ).then(
            fn=on_chat_complete,
            outputs=[history_html, storage_tree, system_prompt_html]
        )
        
        # LLM Settings events
        model_dropdown.change(fn=update_model, inputs=[model_dropdown], outputs=[settings_status])
        temperature_slider.change(fn=update_temperature, inputs=[temperature_slider], outputs=[settings_status])
        max_tokens_slider.change(fn=update_max_tokens, inputs=[max_tokens_slider], outputs=[settings_status])
        top_p_slider.change(fn=update_top_p, inputs=[top_p_slider], outputs=[settings_status])
        repeat_penalty_slider.change(fn=update_repeat_penalty, inputs=[repeat_penalty_slider], outputs=[settings_status])
        num_ctx_slider.change(fn=update_num_ctx, inputs=[num_ctx_slider], outputs=[settings_status])
        max_steps_slider.change(fn=update_max_steps, inputs=[max_steps_slider], outputs=[settings_status])
        base_url_input.change(fn=update_base_url, inputs=[base_url_input], outputs=[settings_status])
        
        refresh_models_btn.click(
            fn=refresh_models,
            inputs=[base_url_input],
            outputs=[model_dropdown, settings_status]
        )
        
        reset_btn.click(
            fn=reset_settings,
            outputs=[
                model_dropdown, temperature_slider, max_tokens_slider,
                top_p_slider, repeat_penalty_slider, num_ctx_slider,
                max_steps_slider, base_url_input, settings_status
            ]
        )
        
        # File management events
        upload_btn.click(
            fn=upload_files,
            inputs=[file_upload],
            outputs=[file_list_html, file_status]
        ).then(
            fn=lambda: gr.update(choices=get_file_choices()),
            outputs=[file_select]
        )
        
        delete_selected_btn.click(
            fn=delete_selected_files,
            inputs=[file_select],
            outputs=[file_list_html, file_status, file_select]
        )
        
        delete_all_btn.click(
            fn=delete_all_files,
            outputs=[file_list_html, file_status, file_select]
        )
        
        refresh_files_btn.click(
            fn=refresh_file_list,
            outputs=[file_list_html, file_select]
        )
        
        # SharedStorage events
        refresh_storage_btn.click(fn=refresh_shared_storage, outputs=[storage_tree])
        
        # History events
        refresh_history_btn.click(fn=get_history_html, outputs=[history_html])
        
        # HTML Preview events
        preview_btn.click(
            fn=preview_html,
            inputs=[html_hash_input],
            outputs=[html_preview_frame, html_preview_status]
        )
        
        copy_btn.click(
            fn=get_html_source,
            inputs=[html_hash_input],
            outputs=[html_source_text, html_preview_status]
        )
        
        # System Prompt events
        refresh_prompt_btn.click(fn=refresh_system_prompt, outputs=[system_prompt_html])
    
    return app


# =============================================================================
# Main
# =============================================================================

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("=" * 60)
    print("Multi-Agent Chatbot")
    print("=" * 60)
    
    app = create_ui()
    app.launch(
        server_name="localhost",
        server_port=7860,
        share=False
    )


if __name__ == "__main__":
    main()
