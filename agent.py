#!/usr/bin/env python3
"""
LLM Agent with Ollama - V2 (JSON Mode)

ê°œì„  ì‚¬í•­:
1. JSON Modeë¥¼ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ íŒŒì‹± ì•ˆì •ì„± í–¥ìƒ
2. ìœ ì—°í•œ ì‘ë‹µ êµ¬ì¡° (tool_call, response, clarification)
3. í–¥ìƒëœ ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„ ë¡œì§
4. ê¸°ì¡´ $key.field ì°¸ì¡° ì‹œìŠ¤í…œ ìœ ì§€
"""

import os
import json
import sys
import threading
import urllib.parse
import urllib.request
from typing import List, Dict, Any, Optional, Callable
from datetime import datetime
from pathlib import Path
from tkinter import messagebox


try:
    import tkinter as tk
    from tkinter import scrolledtext, ttk
except ImportError:
    print("Error: tkinter not installed")
    print("Run: sudo apt-get install python3-tk")
    sys.exit(1)


# ============================================================================
# ì „ì—­ ë³€ìˆ˜ - ì €ì¥ì†Œ
# ============================================================================

TOOL_RESULT_STORAGE: Dict[str, Any] = {}

# LLM í´ë¼ì´ì–¸íŠ¸ ì°¸ì¡° (ask_llmì—ì„œ ì‚¬ìš©)
_OLLAMA_CLIENT: Optional['OllamaClient'] = None
_CURRENT_MODEL: Optional[str] = None

# ============================================================================
# Tool ê²°ê³¼ ì €ì¥ì†Œ ê´€ë¦¬ í•¨ìˆ˜
# ============================================================================

def store_tool_result(key: str, data: Any) -> None:
    """Tool ì‹¤í–‰ ê²°ê³¼ë¥¼ ì €ì¥"""
    global TOOL_RESULT_STORAGE
    TOOL_RESULT_STORAGE[key] = data


def resolve_references(arguments: Dict[str, Any]) -> Dict[str, Any]:
    """
    ì¸ìì—ì„œ $key ì°¸ì¡°ë¥¼ ì‹¤ì œ ê°’ìœ¼ë¡œ ì¹˜í™˜

    ì§€ì›í•˜ëŠ” ì°¸ì¡° í˜•ì‹:
    1. ê°’ ì „ì²´ê°€ ì°¸ì¡°ì¸ ê²½ìš°:
       - {"context": "$source_code.content"} â†’ {"context": "íŒŒì¼ ë‚´ìš©..."}
    
    2. ë¬¸ìì—´ ë‚´ë¶€ì— ì°¸ì¡°ê°€ í¬í•¨ëœ ê²½ìš°:
       - {"query": "ë¶„ì„í•´ì¤˜: $source_code.content"} â†’ {"query": "ë¶„ì„í•´ì¤˜: íŒŒì¼ ë‚´ìš©..."}
    
    ì°¸ì¡° ë¬¸ë²•:
    - $key: ì „ì²´ ê°’
    - $key.field: íŠ¹ì • í•„ë“œ
    - $key.field[0]: ë°°ì—´ ì¸ë±ìŠ¤
    - $key.field[0].subfield: ì¤‘ì²© ì ‘ê·¼
    """
    resolved = {}

    for param_name, param_value in arguments.items():
        if isinstance(param_value, str):
            resolved[param_name] = _resolve_string_references(param_value)
        else:
            resolved[param_name] = param_value

    return resolved

def _resolve_string_references(text: str) -> Any:
    """
    ë¬¸ìì—´ ë‚´ì˜ ëª¨ë“  $key.field ì°¸ì¡°ë¥¼ ì¹˜í™˜
    
    - ë¬¸ìì—´ ì „ì²´ê°€ ë‹¨ì¼ ì°¸ì¡°ë©´ í•´ë‹¹ íƒ€ì… ê·¸ëŒ€ë¡œ ë°˜í™˜ (dict, list ë“±)
    - ë¬¸ìì—´ ë‚´ì— ì°¸ì¡°ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ë¬¸ìì—´ë¡œ ì¹˜í™˜
    """
    import re
    
    # $key ë˜ëŠ” $key.field ë˜ëŠ” $key.field[0] íŒ¨í„´ ë§¤ì¹­
    # ë‹¨ì–´ ê²½ê³„ë‚˜ ë¬¸ìì—´ ëì—ì„œ ëë‚˜ë„ë¡ í•¨
    pattern = r'\$([a-zA-Z_][a-zA-Z0-9_]*(?:\.[a-zA-Z_][a-zA-Z0-9_]*|\[\d+\])*)'

    matches = list(re.finditer(pattern, text))

    if not matches:
        # ì°¸ì¡° ì—†ìŒ - ì›ë³¸ ë°˜í™˜
        return text
    
    # ë¬¸ìì—´ ì „ì²´ê°€ ë‹¨ì¼ ì°¸ì¡°ì¸ ê²½ìš° (ì•ë’¤ ê³µë°± í—ˆìš©)
    if len(matches) == 1:
        match = matches[0]
        if text.strip() == match.group(0):
            # ì „ì²´ê°€ ì°¸ì¡° â†’ ì›ë˜ íƒ€ì… ìœ ì§€ (dict, list ë“±)
            ref = match.group(1)
            return _resolve_single_reference(ref, match.group(0))
    
    # ë¬¸ìì—´ ë‚´ì— ì°¸ì¡°ê°€ í¬í•¨ëœ ê²½ìš° â†’ ë¬¸ìì—´ë¡œ ì¹˜í™˜
    result = text
    # ë’¤ì—ì„œë¶€í„° ì¹˜í™˜í•´ì•¼ ì¸ë±ìŠ¤ê°€ ë°€ë¦¬ì§€ ì•ŠìŒ
    for match in reversed(matches):
        ref = match.group(1)
        full_match = match.group(0)
        
        try:
            resolved_value = _resolve_single_reference(ref, full_match)
            # ì¹˜í™˜í•  ê°’ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
            if isinstance(resolved_value, str):
                replacement = resolved_value
            elif isinstance(resolved_value, (dict, list)):
                import json
                replacement = json.dumps(resolved_value, ensure_ascii=False)
            else:
                replacement = str(resolved_value)
            
            result = result[:match.start()] + replacement + result[match.end():]
        except ValueError:
            # ì°¸ì¡° í•´ì„ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ìœ ì§€í•˜ì§€ ì•Šê³  ì—ëŸ¬ ë°œìƒ
            raise
    
    return result

def _resolve_single_reference(ref: str, original: str) -> Any:
    """
    ë‹¨ì¼ ì°¸ì¡°ë¥¼ í•´ì„
    
    ref: "files_to_delete.files[0]" í˜•íƒœ
    original: "$files_to_delete.files[0]" (ì—ëŸ¬ ë©”ì‹œì§€ìš©)
    """
    import re
    
    # ì²« ë²ˆì§¸ ë¶€ë¶„ (storage key) ì¶”ì¶œ
    if "." in ref:
        key, rest = ref.split(".", 1)
    else:
        key = ref
        rest = None
    
    # Storageì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    data = TOOL_RESULT_STORAGE.get(key)
    if data is None:
        raise ValueError(f"Reference '{original}' not found. Available keys: {list(TOOL_RESULT_STORAGE.keys())}")
    
    # ì¶”ê°€ ê²½ë¡œê°€ ì—†ìœ¼ë©´ ì „ì²´ ë°˜í™˜
    if rest is None:
        return data
    
    # ê²½ë¡œ íŒŒì‹±: "files[0].name" -> ["files", "[0]", "name"]
    # ì •ê·œì‹ìœ¼ë¡œ í•„ë“œëª…ê³¼ ì¸ë±ìŠ¤ë¥¼ ë¶„ë¦¬
    tokens = re.findall(r'(\w+)|\[(\d+)\]', rest)
    
    current = data
    path_so_far = f"${key}"
    
    for token in tokens:
        field_name, index = token
        
        if field_name:
            # ë”•ì…”ë„ˆë¦¬ í•„ë“œ ì ‘ê·¼
            path_so_far += f".{field_name}"
            
            if not isinstance(current, dict):
                raise ValueError(f"Cannot access field '{field_name}' on non-dict type at '{path_so_far}'")
            
            if field_name not in current:
                available = list(current.keys()) if isinstance(current, dict) else 'N/A'
                raise ValueError(f"Field '{field_name}' not found at '{path_so_far}'. Available fields: {available}")
            
            current = current[field_name]
        
        elif index:
            # ë°°ì—´ ì¸ë±ìŠ¤ ì ‘ê·¼
            idx = int(index)
            path_so_far += f"[{idx}]"
            
            if not isinstance(current, (list, tuple)):
                raise ValueError(f"Cannot use index [{idx}] on non-list type at '{path_so_far}'")
            
            if idx < 0 or idx >= len(current):
                raise ValueError(f"Index [{idx}] out of range at '{path_so_far}'. List has {len(current)} items (0-{len(current)-1})")
            
            current = current[idx]
    
    return current


def make_return_object(data: Dict[str, Any]) -> Dict[str, Any]:
    """í‘œì¤€í™”ëœ ë°˜í™˜ ê°ì²´ ìƒì„±"""
    base = {
        "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "created_by": sys._getframe(1).f_code.co_name
    }
    return {**base, **data}


def get_storage_summary() -> str:
    """í˜„ì¬ ì €ì¥ì†Œ ìƒíƒœ ìš”ì•½"""
    if not TOOL_RESULT_STORAGE:
        return "ì €ì¥ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    summary = []
    for key, value in TOOL_RESULT_STORAGE.items():
        if isinstance(value, dict):
            fields = list(value.keys())
            summary.append(f"${key}: {fields}")
        else:
            summary.append(f"${key}: {type(value).__name__}")
    return ", ".join(summary)


# ============================================================================
# ë„êµ¬ ì •ì˜
# ============================================================================

def get_file(base_dir: str = ".", pattern: str = "*") -> Dict[str, Any]:
    """í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¬ê·€ì ìœ¼ë¡œ ëª¨ë“  íŒŒì¼ì„ ìƒëŒ€ ê²½ë¡œë¡œ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜."""
    try:
        base_path = Path(base_dir).resolve()

        if not base_path.exists():
            return make_return_object({
                "result": "failure",
                "base_dir": base_dir,
                "error": f"Directory '{base_dir}' does not exist"
            })

        if pattern == "*":
            all_files = [str(f.relative_to(base_path)) for f in base_path.rglob("*") if f.is_file()]
        else:
            all_files = [str(f.relative_to(base_path)) for f in base_path.rglob(pattern) if f.is_file()]

        return make_return_object({
            "result": "success",
            "base_dir": str(base_path),
            "files": sorted(all_files),
            "count": len(all_files)
        })

    except Exception as e:
        return make_return_object({
            "result": "failure",
            "base_dir": base_dir,
            "error": str(e)
        })


def read_file(file_path: str, encoding: str = "utf-8") -> Dict[str, Any]:
    """íŒŒì¼ì˜ ë‚´ìš©ì„ ì½ì–´ì˜¤ëŠ” í•¨ìˆ˜."""
    try:
        if not os.path.exists(file_path):
            return make_return_object({
                "result": "failure",
                "filename": file_path,
                "error": f"File '{file_path}' does not exist"
            })

        with open(file_path, 'r', encoding=encoding) as f:
            content = f.read()

        file_size = os.path.getsize(file_path)

        return make_return_object({
            "result": "success",
            "filename": file_path,
            "content": content,
            "size": file_size
        })

    except Exception as e:
        return make_return_object({
            "result": "failure",
            "filename": file_path,
            "error": str(e)
        })


def write_file(file_path: str, content: object) -> Dict[str, Any]:
    """íŒŒì¼ì„ ì €ì¥í•˜ëŠ” í•¨ìˆ˜."""
    try:
        dir_path = os.path.dirname(file_path)

        if dir_path and not os.path.exists(dir_path):
            os.makedirs(dir_path, exist_ok=True)

        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(str(content))

        file_size = os.path.getsize(file_path)

        return make_return_object({
            "result": "success",
            "filename": file_path,
            "size": file_size
        })

    except Exception as e:
        return make_return_object({
            "result": "failure",
            "filename": file_path,
            "error": str(e)
        })


def delete_file(file_path: str) -> Dict[str, Any]:
    """íŒŒì¼ì„ ì‚­ì œí•˜ëŠ” í•¨ìˆ˜."""
    try:
        if not os.path.exists(file_path):
            return make_return_object({
                "result": "failure",
                "filename": file_path,
                "error": f"File '{file_path}' does not exist"
            })

        os.remove(file_path)
        return make_return_object({
            "result": "success",
            "filename": file_path
        })

    except Exception as e:
        return make_return_object({
            "result": "failure",
            "filename": file_path,
            "error": str(e)
        })


def ask_llm(query: str, context: str = "") -> Dict[str, Any]:
    """LLMì— ì¿¼ë¦¬ë¥¼ ë³´ë‚´ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜."""
    global _OLLAMA_CLIENT, _CURRENT_MODEL

    try:
        if _OLLAMA_CLIENT is None or _CURRENT_MODEL is None:
            return make_return_object({
                "result": "failure",
                "error": "LLM client not initialized. Please connect first."
            })

        if context:
            full_prompt = f"""Context:
{context}

Request:
{query}

Please provide a detailed and helpful response."""
        else:
            full_prompt = query

        messages = [{"role": "user", "content": full_prompt}]

        # Non-streaming, no JSON mode (ììœ  í˜•ì‹ ì‘ë‹µ)
        response = _OLLAMA_CLIENT.chat_simple(
            model=_CURRENT_MODEL,
            messages=messages,
            temperature=0.7,
            max_tokens=4000
        )

        return make_return_object({
            "result": "success",
            "response": response
        })

    except Exception as e:
        return make_return_object({
            "result": "failure",
            "error": str(e)
        })


# Tool ë ˆì§€ìŠ¤íŠ¸ë¦¬
TOOLS = {
    "get_file": {
        "function": get_file,
        "description": "Recursively get all files in a directory with relative paths",
        "parameters": {
            "base_dir": {
                "type": "string",
                "required": False,
                "default": ".",
                "description": "Base directory to search from (default: current directory)"
            },
            "pattern": {
                "type": "string",
                "required": False,
                "default": "*",
                "description": "File pattern to match (e.g., '*.c', '*.py', default: '*' for all files)"
            }
        }
    },
    "read_file": {
        "function": read_file,
        "description": "Read the contents of a file",
        "parameters": {
            "file_path": {
                "type": "string",
                "required": True,
                "description": "Path to the file to read"
            },
            "encoding": {
                "type": "string",
                "required": False,
                "default": "utf-8",
                "description": "File encoding (default: utf-8)"
            }
        }
    },
    "write_file": {
        "function": write_file,
        "description": "Write content to a file",
        "parameters": {
            "file_path": {
                "type": "string",
                "required": True,
                "description": "Path where the file should be written"
            },
            "content": {
                "type": "string",
                "required": True,
                "description": "Content to write to the file. Use $key.field reference for stored data"
            }
        }
    },
    "delete_file": {
        "function": delete_file,
        "description": "Delete a file",
        "parameters": {
            "file_path": {
                "type": "string",
                "required": True,
                "description": "Path to the file to delete"
            }
        }
    },
    "ask_llm": {
        "function": ask_llm,
        "description": "Send a query to LLM for analysis. Result is stored and accessible as $key.response",
        "parameters": {
            "query": {
                "type": "string",
                "required": True,
                "description": "The question or request to send to LLM"
            },
            "context": {
                "type": "string",
                "required": False,
                "default": "",
                "description": "Additional context like file content (use $key.content reference)"
            }
        }
    }
}


# ============================================================================
# Ollama í´ë¼ì´ì–¸íŠ¸
# ============================================================================

class OllamaClient:
    """Ollama API í´ë¼ì´ì–¸íŠ¸ - JSON Mode ì§€ì›"""

    def __init__(self, base_url: str = "http://192.168.0.30:11434"):
        self.base_url = base_url

    def _request(self, endpoint: str, payload: dict, timeout: int = 1800) -> dict:
        """HTTP ìš”ì²­ ê³µí†µ ë¡œì§"""
        headers = {'Content-Type': 'application/json'}
        data = json.dumps(payload).encode('utf-8')
        req = urllib.request.Request(f"{self.base_url}{endpoint}", data=data, headers=headers)
        
        with urllib.request.urlopen(req, timeout=timeout) as response:
            if response.getcode() != 200:
                raise Exception(f"Ollama API error: {response.getcode()}")
            return json.loads(response.read().decode('utf-8'))

    def chat_simple(self, model: str, messages: List[Dict], 
                    temperature: float = 0.7, max_tokens: int = 4000) -> str:
        """ë‹¨ìˆœ ì±„íŒ… (ìŠ¤íŠ¸ë¦¬ë° ì—†ìŒ, JSON ëª¨ë“œ ì—†ìŒ)"""
        payload = {
            "model": model,
            "messages": messages,
            "stream": False,
            "options": {
                "temperature": temperature,
                "num_predict": max_tokens
            }
        }
        result = self._request("/api/chat", payload)
        return result["message"]["content"]

    def chat_json_mode(self, model: str, messages: List[Dict],
                       temperature: float = 0.7, max_tokens: int = 4000) -> dict:
        """
        â­ JSON Mode ì±„íŒ… - í•­ìƒ ìœ íš¨í•œ JSON ë°˜í™˜
        """
        payload = {
            "model": model,
            "messages": messages,
            "stream": False,
            "format": "json",  # â­ JSON ì¶œë ¥ ê°•ì œ
            "options": {
                "temperature": temperature,
                "num_predict": max_tokens
            }
        }
        result = self._request("/api/chat", payload)
        content = result["message"]["content"]
        
        # JSON íŒŒì‹± (format: jsonì´ë¯€ë¡œ í•­ìƒ ìœ íš¨í•´ì•¼ í•¨)
        try:
            return json.loads(content)
        except json.JSONDecodeError as e:
            # ë§Œì•½ì˜ ê²½ìš° ì—ëŸ¬ ì²˜ë¦¬
            raise Exception(f"JSON parsing failed despite format:json - {e}\nContent: {content[:500]}")

# ============================================================================
# Agent - JSON Mode (ê¸°ë³¸)
# ============================================================================

class OllamaAgentJsonMode:
    """JSON Modeë¥¼ ì‚¬ìš©í•˜ëŠ” Agent (ê¶Œì¥)"""

    def __init__(self, ollama_url: str, model: str):
        global _OLLAMA_CLIENT, _CURRENT_MODEL

        self.ollama = OllamaClient(ollama_url)
        self.model = model
        self.conversation_history = []

        _OLLAMA_CLIENT = self.ollama
        _CURRENT_MODEL = self.model

    def _create_system_prompt(self) -> str:
        """JSON Modeìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸"""
        
        # Tool ì„¤ëª… ìƒì„±
        tools_desc = []
        for name, info in TOOLS.items():
            params_desc = []
            for param_name, param_info in info['parameters'].items():
                req = "required" if param_info['required'] else "optional"
                p_str = f"{param_name} ({param_info['type']}, {req})"
                if 'default' in param_info:
                    p_str += f" default={param_info['default']}"
                params_desc.append(p_str)
            
            tools_desc.append(f"- {name}: {info['description']}\n  Parameters: {', '.join(params_desc) if params_desc else 'none'}")

        tools_text = "\n".join(tools_desc)
        
        # í˜„ì¬ ì €ì¥ì†Œ ìƒíƒœ
        storage_info = get_storage_summary()

        return f"""You are a WiFi driver development assistant.

CRITICAL: Always respond with valid JSON only. No other text.

RESPONSE TYPES (choose one):

1. When you need to use a tool:
{{
    "type": "tool_call",
    "tool": "tool_name",
    "arguments": {{"param": "value"}},
    "store_as": "key_name",
    "reasoning": "brief explanation why this tool is needed"
}}

2. When you have a final answer:
{{
    "type": "response",
    "content": "your detailed response here in Korean."
}}

3. When you need clarification:
{{
    "type": "clarification",
    "question": "what information do you need?"
}}

AVAILABLE TOOLS:
{tools_text}

REFERENCE SYSTEM:
- Results are stored with the key in "store_as"
- Use $key or $key.field in arguments to reference stored data
- Use $key.field[index] to access array elements (0-based index)
- Example: {{"file_path": "$file_list.files[0]"}} references first file from stored key "file_list"

CURRENT STORAGE: {storage_info}

IMPORTANT RULES:
- All JSON keys and string values must use double quotes
- Use $key.field references instead of embedding large content
- Use $key.field[0], $key.field[1], etc. to access individual array items
- Always provide "store_as" for tool calls to enable chaining
- Respond in the same language as the user

Example of field references:
- $key.content: File content from read_file
- $key.files: File list from get_file (array)
- $key.files[0]: First file path from get_file
- $key.files[1]: Second file path from get_file
- $key.response: LLM response from ask_llm
- $key.result: Success/failure status
- $key.count: Number of items (from get_file)"""

    def _validate_tool_call(self, tool_name: str, arguments: Dict[str, Any]) -> Optional[str]:
        """Tool call ìœ íš¨ì„± ê²€ì‚¬. ì—ëŸ¬ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€ ë°˜í™˜, ì„±ê³µ ì‹œ None"""
        if tool_name not in TOOLS:
            return f"Unknown tool: {tool_name}. Available tools: {list(TOOLS.keys())}"
        
        tool_info = TOOLS[tool_name]
        params = tool_info["parameters"]
        
        # Required íŒŒë¼ë¯¸í„° ê²€ì¦
        for param_name, param_info in params.items():
            if param_info.get("required", False) and param_name not in arguments:
                return f"Missing required parameter: '{param_name}' for tool '{tool_name}'"
        
        # Unknown íŒŒë¼ë¯¸í„° ê²€ì¦
        valid_params = set(params.keys())
        provided_params = set(arguments.keys())
        unknown = provided_params - valid_params
        if unknown:
            return f"Unknown parameters: {unknown}. Valid parameters: {valid_params}"
        
        return None

    def _execute_tool(self, tool_name: str, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Tool ì‹¤í–‰"""
        # ìœ íš¨ì„± ê²€ì‚¬
        error = self._validate_tool_call(tool_name, arguments)
        if error:
            return {"result": "failure", "error": error}
        
        try:
            # $key ì°¸ì¡° í•´ê²°
            resolved_args = resolve_references(arguments)
            
            # ê¸°ë³¸ê°’ ì ìš©
            for param_name, param_info in TOOLS[tool_name]["parameters"].items():
                if param_name not in resolved_args and "default" in param_info:
                    resolved_args[param_name] = param_info["default"]
            
            return TOOLS[tool_name]["function"](**resolved_args)
        except ValueError as e:
            return {"result": "failure", "error": f"Reference error: {str(e)}"}
        except Exception as e:
            return {"result": "failure", "error": str(e)}

    def _summarize_result(self, result: Dict[str, Any], store_as: Optional[str]) -> str:
        """Tool ê²°ê³¼ ìš”ì•½"""
        if not isinstance(result, dict):
            return str(result)[:200]
        
        summary_parts = []
        
        if "result" in result:
            summary_parts.append(f"status: {result['result']}")
        
        if "error" in result:
            summary_parts.append(f"error: {result['error']}")
            return "{" + ", ".join(summary_parts) + "}"
        
        for key, value in result.items():
            if key in ["result", "error", "created_at", "created_by"]:
                continue
            
            if isinstance(value, str):
                if len(value) > 100:
                    summary_parts.append(f"{key}: <{len(value)} chars>")
                else:
                    display = value[:50] + "..." if len(value) > 50 else value
                    summary_parts.append(f'{key}: "{display}"')
            elif isinstance(value, list):
                summary_parts.append(f"{key}: [{len(value)} items]")
            elif isinstance(value, dict):
                summary_parts.append(f"{key}: {{...}}")
            else:
                summary_parts.append(f"{key}: {value}")
        
        summary = "{" + ", ".join(summary_parts) + "}"
        
        if store_as:
            fields = [k for k in result.keys() if k not in ["result", "created_at", "created_by"]]
            summary += f"\nâ†’ Stored as ${store_as}"
            if fields:
                summary += f" (fields: {', '.join(fields[:5])})"
        
        return summary

    def chat(self, user_message: str, 
             stream_callback: Callable[[str], None] = None,
             status_callback: Callable[[str], None] = None,
             confirm_callback: Callable[[str, Dict], bool] = None,
             max_iterations: int = 10,
             max_tokens: int = 4000) -> str:
        """
        â­ JSON Mode Agent ë©”ì¸ ë£¨í”„
        """
        self.conversation_history.append({
            "role": "user",
            "content": user_message
        })

        for iteration in range(max_iterations):
            if status_callback:
                status_callback(f"ğŸ”„ Iteration {iteration + 1}")

            messages = [
                {"role": "system", "content": self._create_system_prompt()}
            ] + self.conversation_history

            try:
                # â­ JSON Mode í˜¸ì¶œ
                response = self.ollama.chat_json_mode(
                    model=self.model,
                    messages=messages,
                    temperature=0.7,
                    max_tokens=max_tokens
                )
                
                # ìŠ¤íŠ¸ë¦¬ë° ì½œë°±ìœ¼ë¡œ ì‘ë‹µ í‘œì‹œ
                if stream_callback:
                    stream_callback(json.dumps(response, indent=2, ensure_ascii=False))

                response_type = response.get("type", "unknown")

                # ===== ìµœì¢… ì‘ë‹µ =====
                if response_type == "response":
                    content = response.get("content", "")
                    self.conversation_history.append({
                        "role": "assistant",
                        "content": json.dumps(response, ensure_ascii=False)
                    })
                    if status_callback:
                        status_callback("âœ… Complete")
                    return content

                # ===== ëª…í™•í™” ìš”ì²­ =====
                elif response_type == "clarification":
                    question = response.get("question", "ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?")
                    self.conversation_history.append({
                        "role": "assistant",
                        "content": json.dumps(response, ensure_ascii=False)
                    })
                    if status_callback:
                        status_callback("â“ Clarification needed")
                    return f"ì§ˆë¬¸: {question}"

                # ===== Tool í˜¸ì¶œ =====
                elif response_type == "tool_call":
                    tool_name = response.get("tool", "")
                    arguments = response.get("arguments", {})
                    store_as = response.get("store_as")
                    reasoning = response.get("reasoning", "")

                    if reasoning and stream_callback:
                        stream_callback(f"\n\nğŸ’­ Reasoning: {reasoning}")

                    # ì‚¬ìš©ì í™•ì¸
                    if confirm_callback:
                        if status_callback:
                            status_callback("â¸ï¸ Waiting for confirmation...")
                        
                        if not confirm_callback(tool_name, arguments):
                            if status_callback:
                                status_callback("âŒ Tool execution cancelled")
                            return "Tool execution was cancelled by user. How would you like to proceed?"

                    if status_callback:
                        status_callback(f"ğŸ”§ Executing: {tool_name}")

                    # Tool ì‹¤í–‰
                    tool_result = self._execute_tool(tool_name, arguments)

                    # ê²°ê³¼ ì €ì¥
                    if store_as and tool_result.get("result") == "success":
                        store_tool_result(store_as, tool_result)
                        if status_callback:
                            status_callback(f"ğŸ’¾ Stored as: ${store_as}")

                    if status_callback:
                        status_callback("ğŸ“Š Tool completed")

                    # ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
                    self.conversation_history.append({
                        "role": "assistant",
                        "content": json.dumps(response, ensure_ascii=False)
                    })

                    # Tool ê²°ê³¼ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ
                    result_summary = self._summarize_result(tool_result, store_as)
                    tool_result_json = {
                        "type": "tool_result",
                        "tool": tool_name,
                        "success": tool_result.get("result") == "success",
                        "summary": result_summary,
                        "stored_as": store_as,
                        "available_storage": get_storage_summary()
                    }

                    self.conversation_history.append({
                        "role": "user",
                        "content": json.dumps(tool_result_json, ensure_ascii=False)
                    })

                    if stream_callback:
                        stream_callback(f"\n\nğŸ“Š Result:\n{result_summary}\n\n")

                else:
                    # Unknown type
                    if status_callback:
                        status_callback(f"âš ï¸ Unknown response type: {response_type}")
                    return f"Unexpected response type: {response_type}"

            except Exception as e:
                if status_callback:
                    status_callback(f"âŒ Error: {str(e)}")
                
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ ë©”ì‹œì§€
                if "JSON" in str(e):
                    self.conversation_history.append({
                        "role": "user",
                        "content": json.dumps({
                            "type": "system_error",
                            "error": "Invalid JSON response. Please respond with valid JSON only.",
                            "hint": "Ensure all keys and string values use double quotes"
                        })
                    })
                    continue
                
                return f"Error: {str(e)}"

        return "Max iterations reached"

    def reset(self):
        """ëŒ€í™” ë° ì €ì¥ì†Œ ì´ˆê¸°í™”"""
        global TOOL_RESULT_STORAGE
        self.conversation_history = []
        TOOL_RESULT_STORAGE = {}


# ============================================================================
# GUI
# ============================================================================

class AgentGUI:
    """GUI Application"""

    def __init__(self, root):
        self.root = root
        self.root.title("Agent V2 ğŸ¤– (JSON Mode)")
        self.root.geometry("1100x850")

        self.agent = None
        self.processing = False
        self.confirm_tool_execution = tk.BooleanVar(value=True)

        self.setup_ui()

    def setup_ui(self):
        """UI êµ¬ì„±"""

        # ===== ì„¤ì • í”„ë ˆì„ =====
        config_frame = ttk.LabelFrame(self.root, text="âš™ï¸ Ollama ì„¤ì •", padding=10)
        config_frame.pack(fill=tk.X, padx=10, pady=5)

        # Row 1: URL, Model, Connect
        ttk.Label(config_frame, text="URL:").grid(row=0, column=0, padx=5, sticky=tk.W)
        self.url_entry = ttk.Entry(config_frame, width=30)
        self.url_entry.insert(0, "http://192.168.0.30:11434")
        self.url_entry.grid(row=0, column=1, padx=5)

        ttk.Label(config_frame, text="Model:").grid(row=0, column=2, padx=5, sticky=tk.W)
        self.model_var = tk.StringVar(value="llama3.1")
        self.model_entry = ttk.Combobox(config_frame, textvariable=self.model_var, 
                                         state="readonly", width=25)
        self.model_entry.bind("<<ComboboxSelected>>", self._on_model_change)
        self.model_entry.grid(row=0, column=3, padx=5)

        self.refresh_btn = ttk.Button(config_frame, text="ğŸ”„ Connect", command=self.connect)
        self.refresh_btn.grid(row=0, column=4, padx=10)

        self.status_label = ttk.Label(config_frame, text="â— Not connected", foreground="red")
        self.status_label.grid(row=0, column=5, padx=10)

        # Row 2: Max tokens, Confirm
        ttk.Label(config_frame, text="Max tokens:").grid(row=1, column=0, padx=5, sticky=tk.W, pady=5)
        self.max_tokens_var = tk.IntVar(value=4000)
        max_tokens_spinbox = ttk.Spinbox(config_frame, from_=1000, to=32000, 
                                          increment=1000, textvariable=self.max_tokens_var, width=8)
        max_tokens_spinbox.grid(row=1, column=1, padx=5, pady=5, sticky=tk.W)

        confirm_check = ttk.Checkbutton(config_frame, text="Confirm tool execution",
                                        variable=self.confirm_tool_execution)
        confirm_check.grid(row=1, column=2, padx=10, pady=5)

        # ===== ì±„íŒ… ì˜ì—­ =====
        chat_frame = ttk.LabelFrame(self.root, text="ğŸ’¬ Conversation", padding=10)
        chat_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=5)

        paned = ttk.PanedWindow(chat_frame, orient=tk.HORIZONTAL)
        paned.pack(fill=tk.BOTH, expand=True)

        # ì™¼ìª½: ì±„íŒ… ë””ìŠ¤í”Œë ˆì´
        chat_container = ttk.Frame(paned)
        paned.add(chat_container, weight=3)

        self.chat_display = scrolledtext.ScrolledText(
            chat_container, wrap=tk.WORD, width=70, height=30,
            font=("Consolas", 10), state=tk.DISABLED
        )
        self.chat_display.pack(fill=tk.BOTH, expand=True, pady=(0, 5))

        # ì˜¤ë¥¸ìª½: Storage TreeView
        storage_container = ttk.LabelFrame(paned, text="ğŸ“¦ Storage ($key)", padding=5)
        paned.add(storage_container, weight=1)

        self.storage_tree = ttk.Treeview(storage_container, show="tree headings", columns=("value",))
        self.storage_tree.heading("#0", text="Key", anchor=tk.W)
        self.storage_tree.heading("value", text="Value", anchor=tk.W)
        self.storage_tree.column("#0", width=120, minwidth=80)
        self.storage_tree.column("value", width=200, minwidth=100)

        tree_scroll_y = ttk.Scrollbar(storage_container, orient=tk.VERTICAL, 
                                       command=self.storage_tree.yview)
        tree_scroll_x = ttk.Scrollbar(storage_container, orient=tk.HORIZONTAL, 
                                       command=self.storage_tree.xview)
        self.storage_tree.configure(yscrollcommand=tree_scroll_y.set, 
                                     xscrollcommand=tree_scroll_x.set)

        self.storage_tree.grid(row=0, column=0, sticky="nsew")
        tree_scroll_y.grid(row=0, column=1, sticky="ns")
        tree_scroll_x.grid(row=1, column=0, sticky="ew")
        storage_container.grid_rowconfigure(0, weight=1)
        storage_container.grid_columnconfigure(0, weight=1)

        refresh_storage_btn = ttk.Button(storage_container, text="ğŸ”„ Refresh", 
                                          command=self.refresh_storage_tree)
        refresh_storage_btn.grid(row=2, column=0, columnspan=2, pady=5, sticky="ew")

        # íƒœê·¸ ì„¤ì •
        self.chat_display.tag_config("user", foreground="#2196F3", font=("Consolas", 10, "bold"))
        self.chat_display.tag_config("assistant", foreground="#4CAF50", font=("Consolas", 10))
        self.chat_display.tag_config("system", foreground="#FF9800", font=("Consolas", 9, "italic"))
        self.chat_display.tag_config("json", foreground="#9C27B0", font=("Consolas", 9))

        # ===== ì…ë ¥ ì˜ì—­ =====
        input_frame = ttk.Frame(chat_frame)
        input_frame.pack(fill=tk.X)

        self.input_text = tk.Text(input_frame, height=3, font=("Consolas", 10))
        self.input_text.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=(0, 5))
        self.input_text.bind("<Control-Return>", lambda e: self.send_message())

        btn_frame = ttk.Frame(input_frame)
        btn_frame.pack(side=tk.RIGHT, fill=tk.Y)

        self.send_btn = ttk.Button(btn_frame, text="Send\n(Ctrl+Enter)",
                                   command=self.send_message, state=tk.DISABLED)
        self.send_btn.pack(fill=tk.BOTH, expand=True, pady=(0, 5))

        self.reset_btn = ttk.Button(btn_frame, text="Reset\nChat",
                                    command=self.reset_chat, state=tk.DISABLED)
        self.reset_btn.pack(fill=tk.BOTH, expand=True)

        # ===== ë„êµ¬ ì •ë³´ =====
        tools_frame = ttk.LabelFrame(self.root, text="ğŸ”§ Available Tools", padding=10)
        tools_frame.pack(fill=tk.X, padx=10, pady=5)

        tools_text = "  â€¢  ".join([f"{name}" for name in TOOLS.keys()])
        ttk.Label(tools_frame, text=tools_text, font=("Consolas", 9)).pack()

    def _on_model_change(self, event=None):
        """ëª¨ë¸ ë³€ê²½ ì‹œ Agent ì¬ìƒì„±"""
        self._create_agent()

    def _create_agent(self):
        """í˜„ì¬ ì„¤ì •ìœ¼ë¡œ Agent ìƒì„±"""
        if not self.model_var.get():
            return
        
        self.agent = OllamaAgentJsonMode(self.url_entry.get(), self.model_var.get())
        self.append_text(f"[System] Agent created (JSON Mode)\n", "system")

    def refresh_storage_tree(self):
        """Storage TreeView ê°±ì‹ """
        for item in self.storage_tree.get_children():
            self.storage_tree.delete(item)

        for key, value in TOOL_RESULT_STORAGE.items():
            parent_id = self.storage_tree.insert("", tk.END, text=f"${key}", open=True)

            if isinstance(value, dict):
                for field, field_value in value.items():
                    display_value = self._format_tree_value(field_value)
                    self.storage_tree.insert(parent_id, tk.END, text=field, values=(display_value,))
            else:
                display_value = self._format_tree_value(value)
                self.storage_tree.insert(parent_id, tk.END, text="(value)", values=(display_value,))

    def _format_tree_value(self, value: Any) -> str:
        """TreeViewì— í‘œì‹œí•  ê°’ í¬ë§·íŒ…"""
        if isinstance(value, str):
            return f"<{len(value)} chars>" if len(value) > 50 else value
        elif isinstance(value, list):
            return f"[{len(value)} items]"
        elif isinstance(value, dict):
            return f"{{{len(value)} fields}}"
        return str(value)

    def append_text(self, text: str, tag: str = None):
        """í…ìŠ¤íŠ¸ ì¶”ê°€ (thread-safe)"""
        def _append():
            self.chat_display.config(state=tk.NORMAL)
            if tag:
                self.chat_display.insert(tk.END, text, tag)
            else:
                self.chat_display.insert(tk.END, text)
            self.chat_display.see(tk.END)
            self.chat_display.config(state=tk.DISABLED)
        self.root.after(0, _append)

    def set_status(self, text: str, color: str = "black"):
        """ìƒíƒœ ì—…ë°ì´íŠ¸"""
        def _update():
            self.status_label.config(text=text, foreground=color)
        self.root.after(0, _update)

    def confirm_tool_execution_dialog(self, tool_name: str, arguments: Dict[str, Any]) -> bool:
        """ë„êµ¬ ì‹¤í–‰ í™•ì¸ ë‹¤ì´ì–¼ë¡œê·¸"""
        if not self.confirm_tool_execution.get():
            return True

        args_formatted = json.dumps(arguments, indent=2, ensure_ascii=False)
        tool_desc = TOOLS.get(tool_name, {}).get('description', 'No description')

        message = f"""The agent wants to execute a tool:

Tool: {tool_name}
Description: {tool_desc}

Arguments:
{args_formatted}

Do you want to proceed?"""

        return messagebox.askyesno("Confirm Tool Execution", message, icon='question')

    def connect(self):
        """Ollama ì—°ê²°"""
        def _connect():
            try:
                # ëª¨ë¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
                url = urllib.parse.urljoin(self.url_entry.get(), "/api/tags")
                with urllib.request.urlopen(url, timeout=10) as response:
                    data = json.load(response)
                    models = [model["name"] for model in data["models"]]

                def _update_ui():
                    self.model_entry["values"] = models
                    if models:
                        self.model_entry.set(models[0])
                        self._create_agent()
                    self.set_status("â— Connected", "green")
                    self.append_text(f"[System] Connected to {self.url_entry.get()}\n", "system")
                    self.append_text(f"[System] Available models: {', '.join(models)}\n", "system")
                    self.send_btn.config(state=tk.NORMAL)
                    self.reset_btn.config(state=tk.NORMAL)

                self.root.after(0, _update_ui)

            except Exception as e:
                def _show_error():
                    self.set_status("â— Connection failed", "red")
                    self.append_text(f"[System] âŒ Connection failed: {str(e)}\n", "system")
                self.root.after(0, _show_error)

        threading.Thread(target=_connect, daemon=True).start()

    def send_message(self):
        """ë©”ì‹œì§€ ì „ì†¡"""
        if self.processing or not self.agent:
            return

        user_input = self.input_text.get("1.0", tk.END).strip()
        if not user_input:
            return

        self.input_text.delete("1.0", tk.END)
        self.append_text(f"ğŸ‘¤ You:\n", "user")
        self.append_text(f"{user_input}\n\n")

        self.processing = True
        self.send_btn.config(state=tk.DISABLED)
        self.input_text.config(state=tk.DISABLED)

        self.append_text(f"ğŸ¤– Assistant:\n", "assistant")

        def _process():
            try:
                def stream_cb(token):
                    self.append_text(token)

                def status_cb(status):
                    self.append_text(f"\n[{status}]\n", "system")
                    self.root.after(0, self.refresh_storage_tree)

                def confirm_cb(tool_name, arguments):
                    result_container = [None]
                    event = threading.Event()

                    def _ask():
                        result_container[0] = self.confirm_tool_execution_dialog(tool_name, arguments)
                        event.set()

                    self.root.after(0, _ask)
                    event.wait()
                    return result_container[0]

                self.agent.chat(
                    user_input,
                    stream_callback=stream_cb,
                    status_callback=status_cb,
                    confirm_callback=confirm_cb,
                    max_tokens=self.max_tokens_var.get()
                )

                self.append_text("\n\n" + "=" * 80 + "\n\n")

            except Exception as e:
                self.append_text(f"\n\nâŒ Error: {str(e)}\n\n", "system")

            finally:
                self.processing = False
                self.root.after(0, lambda: self.send_btn.config(state=tk.NORMAL))
                self.root.after(0, lambda: self.input_text.config(state=tk.NORMAL))
                self.root.after(0, lambda: self.input_text.focus())

        threading.Thread(target=_process, daemon=True).start()

    def reset_chat(self):
        """ì±„íŒ… ì´ˆê¸°í™”"""
        if self.agent:
            self.agent.reset()

        self.chat_display.config(state=tk.NORMAL)
        self.chat_display.delete("1.0", tk.END)
        self.chat_display.config(state=tk.DISABLED)

        self.refresh_storage_tree()
        self.append_text("[System] Chat reset! ğŸ”„\n\n", "system")


# ============================================================================
# Main
# ============================================================================

def main():
    root = tk.Tk()
    app = AgentGUI(root)
    app.reset_chat()
    root.mainloop()


if __name__ == "__main__":
    main()
